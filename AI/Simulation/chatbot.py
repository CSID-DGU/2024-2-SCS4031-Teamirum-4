from openai import OpenAI
import streamlit as st
import json
import os
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import streamlit.components.v1 as components
#OCR
import pdfplumber
from PIL import Image
import pytesseract

# OpenAI API í‚¤ ì„¤ì •
pytesseract.pytesseract.tesseract_cmd = r"C:/Program Files/Tesseract-OCR/tesseract.exe"
 
# ì¶”ì²œ ê²°ê³¼ë¥¼ JSON íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
# ìƒëŒ€ ê²½ë¡œë¡œ JSON íŒŒì¼ ê²½ë¡œ ì„¤ì •
pdf_dir = '/Users/jjrm_mee/Desktop/2024-2-SCS4031-Teamirum-4/recommendations.json'

# íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
if not os.path.exists(pdf_dir):
    raise FileNotFoundError(f"File not found: {pdf_dir}")

with open(pdf_dir, 'r', encoding='utf-8') as f:
    recommendation_results = json.load(f)

# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜
def clean_text(text):
    text = re.sub(r'\s+', ' ', text)  # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
    text = re.sub(r'[^\w\sã„±-ã…ã…-ã…£ê°€-í£.,!?]', '', text)  # íŠ¹ìˆ˜ë¬¸ì ì œê±°
    return text.strip()

def create_prompt(user_input, recommendation_results):
    rag_results = []
    for rec in recommendation_results:
        try:
            rag_results.append(
                f"Rank {rec.get('rank', 'N/A')}: {rec.get('summary_text', 'ë‚´ìš© ì—†ìŒ')} "
                f"(ìƒí’ˆëª…: {rec.get('product_name', 'ìƒí’ˆëª… ì—†ìŒ')}, "
                f"ìœ ì‚¬ë„ ì ìˆ˜: {rec.get('similarity_score', 0.0):.2f})"
            )
        except KeyError as e:
            rag_results.append(f"ë°ì´í„° ëˆ„ë½: {e}")
    
    references_text = "\n".join(rag_results)

    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ìƒì„±
    system_message = (
        f"ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.\n"
        f"ë‹¤ìŒì€ ê´€ë ¨ ì°¸ê³ ìë£Œì…ë‹ˆë‹¤:\n{references_text}"
    )
    return system_message

# GPT ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def ask_gpt(user_input, recommendation_results):
    terms_dir = "/Users/jjrm_mee/Desktop/2024-2-SCS4031-Teamirum-4/ìƒí’ˆìš”ì•½ì„œ/ì‹¤ì†ë³´í—˜" 
    #terms_dir = os.path.join(os.path.dirname(__file__), "ìƒí’ˆìš”ì•½ì„œ1", "ì‹¤ì†ë³´í—˜")
 
    print(terms_dir)
    
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ìƒì„±
    system_message = create_prompt(user_input, recommendation_results)
    
    
    context = "ì¶”ì²œëœ ë³´í—˜ìƒí’ˆ ëª©ë¡ê³¼ ê´€ë ¨ ë‚´ìš©ì…ë‹ˆë‹¤:\n"
    
    # RAG ê²°ê³¼ë¥¼ ëª…í™•íˆ êµ¬ì¡°í™”
    rag_results = []
    for idx, rec in enumerate(recommendation_results[:3]):
        product_name = rec.get('product_name', 'ìƒí’ˆëª… ì—†ìŒ')
        relevant_text = rec.get('relevant_text', 'ê´€ë ¨ í…ìŠ¤íŠ¸ ì—†ìŒ')
        similarity_score = rec.get('similarity_score', 0.0)
        rag_results.append({
            "rank" : idx+1,
            "product_name" : product_name,
            "relevant_text": relevant_text,
            "similarity_score": similarity_score,
        })
       
         # ì•½ê´€ íŒŒì¼ ì²˜ë¦¬ ë° RAG ê²°ê³¼ ë³´ê°•
        for result in rag_results:
            terms_filename = result["product_name"]  # íŒŒì¼ ì´ë¦„ê³¼ ì•½ê´€ íŒŒì¼ëª…ì´ ì¼ì¹˜ì‹œì¼œì•¼í•¨
            terms_path = os.path.join(terms_dir, terms_filename)
            relevant_text = ""
        
        if os.path.exists(terms_path):
            full_text = ""
            print("ìˆë‚˜ìš©")
            try:
                # ì•½ê´€ íŒŒì¼ ë¡œë“œ
                if terms_path.endswith('.pdf'):
                    with pdfplumber.open(terms_path) as pdf:
                        for page in pdf.pages:
                            page_text = page.extract_text()
                            if page_text:
                                full_text += page_text + " "
                elif terms_path.endswith('.txt'):
                    with open(terms_path, 'r', encoding='utf-8') as f:
                        full_text = f.read()
                else:
                    print(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {terms_filename}")
                    full_text = ""
                
                # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
                full_text = clean_text(full_text)
                sentences = re.split(r'(?<=[.!?])\s+', full_text)[:1000]# ë¬¸ì¥ ìˆ˜ ì œí•œ

                # ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì¥ ì°¾ê¸°
                vectorizer = TfidfVectorizer().fit(sentences)
                sentence_embeddings = vectorizer.transform(sentences)
                user_embedding = vectorizer.transform([user_input])
                
                similarities = cosine_similarity(user_embedding, sentence_embeddings)
                most_similar_idx = similarities.argsort()[0][-1]
                most_similar_sentence = sentences[most_similar_idx]
                
                relevant_text = most_similar_sentence
            except Exception as e:
                print(f"{terms_filename} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                relevant_text = "í•´ë‹¹ ìƒí’ˆì˜ ì•½ê´€ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        else:
            relevant_text = "í•´ë‹¹ ìƒí’ˆì˜ ì•½ê´€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        result['relevant_text'] = relevant_text

    # ë©”ì‹œì§€ êµ¬ì„± (ChatCompletion API í˜•ì‹)
    messages = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ë³´í—˜ ìƒí’ˆì— ëŒ€í•œ ì „ë¬¸ê°€ë¡œì„œ ì‚¬ìš©ìì—ê²Œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."},
        {"role": "user", "content": user_input},
        {"role": "assistant", "content": context},
        {"role": "user", "content": "ìœ„ì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ê°€ì¥ ê´€ë ¨ ìˆëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”."}
    ]

    # GPT í˜¸ì¶œ
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            max_tokens=1000,
            temperature=0.7,
            n=1,
            stop=None,
        )
        answer = response.choices[0].message.content.strip()
        return answer
    except Exception as e:
        return f"Error: {str(e)}"
    

# OCR ì²˜ë¦¬ í•¨ìˆ˜
def ocr_image_to_text(image):
    try:
        text = pytesseract.image_to_string(image, lang='kor')
        return clean_text(text)
    except Exception as e:
        return f"Error during OCR processing: {str(e)}"

#ğŸŸ¢í‘œì‹œ :ì±—ë´‡ UI
# ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢í•´ì‹œíƒœê·¸ ì¶”ì¶œí•¨ìˆ˜
def extract_hashtags(raw_content):
    okt = Okt()
    nouns = okt.nouns(raw_content)
    unique_nouns = list(set(nouns))
    hashtags = " ".join([f"#{noun}" for noun in unique_nouns])
    return hashtags

#ğŸŸ¢ğŸŸ¢ í˜ì´ì§€ ë ˆì´ì•„ì›ƒ ì„¤ì •

st.set_page_config(page_title="í‹°ë¯¸ë£¸ ë³´í—˜ ì±—ë´‡", layout="wide")

# CSS íŒŒì¼ ë¡œë“œ í•¨ìˆ˜
def load_css(file_name):
    with open(file_name, "r", encoding="utf-8") as f:  # ì¸ì½”ë”© ì„¤ì •
        return f"<style>{f.read()}</style>"


# CSS íŒŒì¼ ë¡œë“œ ë° ì ìš©
st.markdown(load_css("styles.css"), unsafe_allow_html=True)

#ìœ ì‚¬ë„ ë‚´ë¦¼ì°¨ìˆœ
recommendation_results_sorted = sorted(
    recommendation_results,
    key=lambda x: x.get("similarity_score", 0.0),
    reverse=True
)

# ì™¼ìª½ ì‚¬ì´ë“œë°”: ì¶”ì²œ ë³´í—˜ TOP3
st.sidebar.markdown(
    """
    <div class="sidebar-container">
        <h2>ì¶”ì²œ ë³´í—˜ TOP 3</h2>
    </div>
    """,
    unsafe_allow_html=True,
)

# ì¶”ì²œ ê²°ê³¼ ì¶œë ¥
for idx,rec in enumerate(recommendation_results):
    product_name = rec.get("product_name", "ìƒí’ˆëª… ì—†ìŒ").replace(".pdf", "")
    similarity_score = rec.get("similarity_score", 0.0)
    reason = rec.get("reason", "")

    # ê´„í˜¸ ì•ˆì˜ ë‚´ìš© ì¶”ì¶œ ë° ì¤‘ë³µ ì œê±°
    if "(" in reason and ")" in reason:
        raw_content = reason[reason.find("(") + 1:reason.find(")")]  # ê´„í˜¸ ì•ˆ ì¶”ì¶œ
        hashtags =  extract_hashtags(raw_content)
    else:
        hashtags = "#ì¶”ì²œì´ìœ  ì—†ìŒ"
    print("hashtags: ", hashtags)

    # ë²”ì£¼í™” ë° ì‹ í˜¸ë“± ìƒ‰ìƒ ì•„ì´ì½˜ ì„¤ì •
    if idx == 0:
        category = "ë§¤ìš° ì í•©"
        icon = "ğŸŸ¢"  # ì´ˆë¡ ì‹ í˜¸ë“±
        font_color = "black"
    elif idx < 3:
        category = "ì í•©"
        icon = "ğŸŸ "  # ì£¼í™© ì‹ í˜¸ë“±
        font_color = "black"
    else:
        break  # ìƒìœ„ 3ê°œê¹Œì§€ë§Œ í‘œì‹œ
    
    # ì™¼ìª½ ì‚¬ì´ë“œë°”ì— í‘œì‹œ
    st.sidebar.markdown(
        f"<div style='font-size:18px; color:{font_color}; font-weight:bold;'>"
        f"<b>{product_name}</b></div>", 
        unsafe_allow_html=True
    )
    st.sidebar.markdown(f"**í‰ê°€**: {icon} ({category})", unsafe_allow_html=False)

    st.sidebar.markdown(
        f"<p style = 'font-size:14px; color:gray;'>ì¶”ì²œ ì´ìœ : {hashtags}</p>",
        unsafe_allow_html=True
    )
    # êµ¬ë¶„ì„  ì¶”ê°€
    st.sidebar.markdown("<hr>", unsafe_allow_html=True)

# ì‚¬ì´ë“œë°”
st.sidebar.markdown(
    """
    <div class="fixed-header header-two">
        <h3>ì±—ë´‡ì—ê²Œ ë¬¼ì–´ë³´ë©´ ì¢‹ì€ ì§ˆë¬¸ LIST !</h3>
        <ul>
            <li>Q. ë³´í—˜ ê°€ì… ì‹œ ê°€ì¥ ì¤‘ìš”í•œ ì ì€?</li>
            <li>Q. ì œ ê¸°ì¤€ì—ì„œ í•´ë‹¹ ë³´í—˜ ê°€ì…ì‹œ ë³´ì¥ ê¸ˆì•¡ì€ ì–¼ë§ˆë‚˜ ë‚˜ì˜¤ë‚˜ìš”?</li>
            <li>Q. ë³´í—˜ ì•½ê´€ì„ í™•ì¸í•˜ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?</li>
            <li>Q. ì¶”ì²œë°›ì€ ë³´í—˜ì˜ ì²­êµ¬ ì ˆì°¨ê°€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?</li>
            <li>Q. ì¶”ì²œë°›ì€ ë³´í—˜ì˜ ë³´í—˜ê¸ˆ ì§€ê¸‰ê¸°ì¤€ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?</li>
            <li>Q. ì¶”ì²œë°›ì€ ë³´í—˜ì˜ í•´ì•½í™˜ê¸‰ê¸ˆì„ ì•Œë ¤ì£¼ì„¸ìš”</li>
        </ul>
    </div>
    """,
    unsafe_allow_html=True,
)

# ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢**ë©”ì¸ ì˜ì—­**: ì±—ë´‡ UI
# í—¤ë”
st.markdown(
    """
    <div class="header">
        <h1>í‹°ë¯¸ë£¸ ë³´í—˜ ì±—ë´‡ ğŸ‘‹</h1>
    </div>
    """,
    unsafe_allow_html=True,
)

# ê³µë°± ì¶”ê°€
st.markdown("<div style='height: 30px;'></div>", unsafe_allow_html=True)

# í°ìƒ‰ ì»¨í…Œì´ë„ˆ ìƒì„±
st.markdown(
    """
    <div style="background-color: #ffffff; padding: 50px; border-radius: 10px; margin: 100px 0;">
    </div>
    """,
    unsafe_allow_html=True,
)

# ê³µë°± ì¶”ê°€
st.markdown("<div style='height: 30px;'></div>", unsafe_allow_html=True)

 #ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ UI

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ëŒ€í™” ì´ë ¥ ê´€ë¦¬
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ë³´í—˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì—ê²Œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."}
    ]
# íŒŒì¼ ì—…ë¡œë“œ UI
uploaded_file = st.file_uploader("ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (PNG, JPG)", type=["png", "jpg", "jpeg"])

#ê³µë°± ì¶”ê°€
st.markdown(
    """
    <div style="background-color: #ffffff; padding: 5px; border-radius: 10px; margin: 5px 0;">
    </div>
    """,
    unsafe_allow_html=True,
)

# ê³µë°± ì¶”ê°€
st.markdown("<div style='height: 30px;'></div>", unsafe_allow_html=True)


user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")

# OCR ì²˜ë¦¬
ocr_text = ""
if uploaded_file:
    image = Image.open(uploaded_file)
    with st.spinner("ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ ì¤‘..."):
        ocr_text = ocr_image_to_text(image)
    st.success("ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")  

 # OCR ë°ì´í„° + ì‚¬ìš©ì ì…ë ¥ ê²°í•©
#combined_input = f"{user_input.strip()} {ocr_text.strip()}".strip()

    
# ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
if user_input:
    assistant_response = ask_gpt(user_input, recommendation_results)
    st.session_state.messages.append({"role": "user", "content": user_input})
    st.session_state.messages.append({"role": "assistant", "content": assistant_response})

    with st.chat_message("user"):
        st.markdown(user_input)
    with st.chat_message("assistant"):
        st.markdown(assistant_response)
else:
    st.write("ì§ˆë¬¸ì„ ì…ë ¥í•˜ê±°ë‚˜ ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
#ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ UI
# í°ìƒ‰ ì»¨í…Œì´ë„ˆ ìƒì„±
st.markdown(
    """
    <div style="background-color: #ffffff; padding: 20px; border-radius: 10px; margin: 20px 0;">
    </div>
    """,
    unsafe_allow_html=True,
)
st.markdown("<div style='height: 30px;'></div>", unsafe_allow_html=True)



# í•˜ë‹¨ ê³ ì • ì½˜í…ì¸ 
st.markdown(
    """
    <div class="fixed-footer">
        <p>
            Â© 2024 í‹°ë¯¸ë£¸ ë³´í—˜ ì±—ë´‡ | ë¬¸ì˜ ì‚¬í•­ì€ 
            <a href="mailto:contact@timeroom.com" style="text-decoration:none; color:#007bff;">
                contact@timeroom.com
            </a>ìœ¼ë¡œ ì—°ë½í•˜ì„¸ìš”.
        </p>
    </div>
    """,
    unsafe_allow_html=True,
)


##############################################
# 13ë“±ë¶„ëœ ì—´ ìƒì„±
col1, col2, col3, col4, col5, col6, col7, col8,col9,col10,col11,col12,col13,col14,col15,col16,col17 = st.columns(17)

image_1_path = "C:/Users/kehah/Desktop/2024-2-SCS4031-Teamirum-4/AI/Simulation/img/receipt.png"
image_2_path = "C:/Users/kehah/Desktop/2024-2-SCS4031-Teamirum-4/AI/Simulation/img/customer-support.png"
image_3_path = "C:/Users/kehah/Desktop/2024-2-SCS4031-Teamirum-4/AI/Simulation/img/insurance-company.png"
image_4_path = "C:/Users/kehah/Desktop/2024-2-SCS4031-Teamirum-4/AI/Simulation/img/qna.png"
image_5_path = "C:/Users/kehah/Desktop/2024-2-SCS4031-Teamirum-4/AI/Simulation/img/heart.png"
link5 = "https://pub.insure.or.kr/#fsection01"
# image_3_path = "images/image3.jpg"



# ì²« ë²ˆì§¸ ì—´ ì½˜í…ì¸ 
with col3:
   st.image(image_1_path, caption="ë³´í—˜ê¸ˆ ê³„ì‚°")

# ë‘ ë²ˆì§¸ ì—´ ì½˜í…ì¸ 
with col6:
    st.image(image_2_path, caption="ê³ ê°ì„¼í„° ì „í™”ë²ˆí˜¸")
   
# ì„¸ ë²ˆì§¸ ì—´ ì½˜í…ì¸ 
with col9:
    st.image(image_3_path, caption="ë³´í—˜ì‚¬ í™ˆí˜ì´ì§€")
# 4 ë²ˆì§¸ ì—´ ì½˜í…ì¸ 
with col12:
    st.image(image_4_path, caption="ìì£¼ ë¬»ëŠ” ì§ˆë¬¸")
# 5 ë²ˆì§¸ ì—´ ì½˜í…ì¸ 
with col15:
    st.image(image_5_path, caption="ìƒëª…ë³´í—˜ ê³µì‹œì‹¤ ë¹„êµ")



##############################################
# ì•„ë˜ìª½ 17ë“±ë¶„ëœ ì—´ ìƒì„±
col1, col2, col3, col4, col5, col6, col7, col8, col9, col10, col11 = st.columns(11)

# ì²« ë²ˆì§¸ ì½˜í…ì¸  (2ì¹¸ ì°¨ì§€)
with col2:
    with st.expander("ë³´í—˜ê¸ˆ ì •ë³´ ë³´ê¸°"):
        st.write("ë³´í—˜ê¸ˆ ê³„ì‚°ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ë¥¼ ì—¬ê¸°ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        st.write("ì˜ˆ: ë³´í—˜ë£Œ ê³„ì‚° ì˜ˆì‹œë‚˜ ë„êµ¬ë¥¼ ì—¬ê¸°ì— ì¶”ê°€.")

# ë‘ ë²ˆì§¸ ì½˜í…ì¸  (2ì¹¸ ì°¨ì§€)
with col4:
    with st.expander("ê³ ê°ì„¼í„°"):
        st.write("4ëŒ€ ìƒëª…ë³´í—˜ ê³ ê°ì„¼í„° ì „í™”ë²ˆí˜¸:")
        st.write("ì‚¼ì„±ìƒëª…: 1588-3114")
        st.write("í•œí™”ìƒëª…: 1566-0100")
        st.write("êµë³´ìƒëª…: 1588-1001")
        st.write("ì‹ í•œë¼ì´í”„: 1588-8000")

# ì„¸ ë²ˆì§¸ ì½˜í…ì¸  (2ì¹¸ ì°¨ì§€)
with col6:
    with st.expander("4ëŒ€ ìƒëª…ë³´í—˜ì‚¬ í™ˆí˜ì´ì§€ ë§í¬"):
        st.write("[ì‚¼ì„±ìƒëª…](https://www.samsunglife.com)")
        st.write("[í•œí™”ìƒëª…](https://www.hanwhalife.com)")
        st.write("[êµë³´ìƒëª…](https://www.kyobo.co.kr)")
        st.write("[ì‹ í•œë¼ì´í”„](https://www.shinhanlife.co.kr)")

# ë„¤ ë²ˆì§¸ ì½˜í…ì¸  (2ì¹¸ ì°¨ì§€)
with col8:
    st.markdown(
        f'<a href="{link5}" target="_blank" style="text-decoration:none; font-size:16px;">ğŸ‘‰ ìƒëª…ë³´í—˜ ê³µì‹œì‹¤ ë°”ë¡œê°€ê¸°</a>',
        unsafe_allow_html=True,
    )

# ë‹¤ì„¯ ë²ˆì§¸ ì½˜í…ì¸  (2ì¹¸ ì°¨ì§€)
with col10:
    st.markdown(
        f'<a href="{link5}" target="_blank" style="text-decoration:none; font-size:16px;">ğŸ‘‰ ìƒëª…ë³´í—˜ ê³µì‹œì‹¤ ë°”ë¡œê°€ê¸°</a>',
        unsafe_allow_html=True,
    )
# ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ UIë
